{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df = pd.read_csv(\"income.csv\", index_col=None, names=[\"income\", \"count\"], skiprows=1)\n",
    "df.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=\"number\")\n",
    "\n",
    "\n",
    "# Create new column\n",
    "df[\"target\"] = iris.target\n",
    "\n",
    "pd.crosstab(df.salary, df.left).plot(kind=\"bar\")\n",
    "\n",
    "\n",
    "inputs.groupby(\"Age\").mean()\n",
    "df.groupby(\"Category\").describe()\n",
    "\n",
    "from word2number import w2n\n",
    "\n",
    "df.experience = df[\"experience\"].apply(w2n.word_to_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.sample(5)\n",
    "df.head(5)\n",
    "df[df.column == 1].head()\n",
    "df[45:55]\n",
    "df.loc[30]\n",
    "df.shape\n",
    "df.columns\n",
    "df.nunique()\n",
    "df.describe()\n",
    "df[\"column\"].describe()\n",
    "df[\"column\"].unique()\n",
    "df[\"column\"].value_counts(ascending=False)\n",
    "df[\"column\"].values\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"column\"], axis=1)\n",
    "df.drop([\"column1\", \"column2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Handle na values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "df.dropna(inplace=True)\n",
    "df = df[df.column.notnull()]\n",
    "df[cols_to_fill_zero] = df[cols_to_fill_zero].fillna(0)\n",
    "df[\"column\"].fillna(df[\"column\"].mean(), inplace=True)\n",
    "df.column = df.column.fillna(df.column.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Handle categorical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction (Rename minor categories as others to reduce no of categories)\n",
    "df5.location = df5.location.apply(\n",
    "    lambda x: \"other\" if x in location_stats_less_than_10 else x\n",
    ")\n",
    "\n",
    "# Creating dummy Variables\n",
    "dummies = pd.get_dummies(df.column)\n",
    "dummies = dummies.astype(\"int\")\n",
    "merged = pd.concat([df, dummies], axis=\"columns\")\n",
    "\n",
    "df = pd.get_dummies(df, dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Handle text values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Bedroom\t-> 4\n",
    "df3[\"bhk\"] = df3[\"size\"].apply(lambda x: int(x.split(\" \")[0]))\n",
    "df3.bhk.unique()\n",
    "\n",
    "# spam -> 1\n",
    "df[\"spam\"] = df[\"Category\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "\n",
    "\n",
    "# explore other than number formats in the feature\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "df3[~df3[\"total_sqft\"].apply(is_float)]\n",
    "\n",
    "\n",
    "# 2100 - 2850  ->  2475\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split(\"-\")\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0]) + float(tokens[1])) / 2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Handle outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution - data points forms a bell curve in histogram plot\n",
    "\n",
    "Mean & Standard Deviation - Referral points in normal distributed curve\n",
    "\n",
    "ZScore - A math & py function which calculates how many sd a data point away from the mean\n",
    "\n",
    "(Math formula-> Datapoint-mean / sd  \n",
    "py method ->\n",
    "\n",
    "For example if mean is 66.37 and standard deviation is 3.84.\n",
    "If a value of a data point is 77.91 then Z score for that is 3 because it is 3 standard deviation away (77.91 = 66.37 + 3 \\* 3.84)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['column'].describe()\n",
    "df.shape[0] - df2.shape[0]\n",
    "\n",
    "\n",
    "#plot histogram to see data distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "plt.xlabel(\"Price per square ft\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.hist(df4.price_per_sqft, bins=20, rwidth=0.8, density=True)\n",
    "rng = np.arange(-5000, df4.price_per_sqft.max(), 100)\n",
    "plt.plot(rng, norm.pdf(rng, df4.price_per_sqft.mean(), df4.price_per_sqft.std()))\n",
    "\n",
    "import seaborn as sn\n",
    "sn.histplot(df.price_per_sqft, kde=True)\n",
    "\n",
    "# Percentile\n",
    "min_thresold, max_thresold = df.price.quantile([0.001,0.999]) #0.1% and 99.9% / [0.01,0.99] #1% and 99%\n",
    "df[df.price<min_thresold]\n",
    "df[df.price<max_thresold]\n",
    "df2 = df[(df.price>min_thresold)&(df.price<max_thresold)]\n",
    "\n",
    "#Standard Deviation\n",
    "upper_limit = df['column'].mean() + 3*df['column'].std()\n",
    "lower_limit = df['column'].mean() - 3*df['column'].std()\n",
    "df[(df['column']>upper_limit) | (df['column']<lower_limit)]\n",
    "df_no_outlier_std_dev = df[(df['column']>lower_limit) & (df['column']<upper_limit)]\n",
    "\n",
    "#ZScore\n",
    "df['zscore'] = ( df['column'] - df['column'].mean() ) / df['column'].std()\n",
    "df[df['zscore']>3]\n",
    "df[df['zscore']<-3]\n",
    "df[(df.zscore<-3) | (df.zscore>3)]\n",
    "df_no_outliers = df[(df.zscore>-3) & (df.zscore<3)]\n",
    "\n",
    "#IQR\n",
    "Q1 = df.height.quantile(0.25)\n",
    "Q3 = df.height.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_limit = Q1 - 1.5*IQR\n",
    "upper_limit = Q3 + 1.5*IQR\n",
    "df[(df.height<lower_limit)|(df.height>upper_limit)]\n",
    "df_no_outlier = df[(df.height>lower_limit)&(df.height<upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "\n",
    "plt.title(\"Flowers\")\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.gray()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.legend()\n",
    "\n",
    "plt.scatter(\n",
    "    df0[\"x\"], df0[\"y\"], color=\"green\", marker=\"+\", label=\"centroid\", linewidth=\"5\"\n",
    ")\n",
    "plt.matshow(digits.images[i])\n",
    "plt.plot(k_rng, sse, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "# log normal distribution\n",
    "sns.set(rc={\"figure.figsize\": (11.7, 8.27)})\n",
    "g = sns.barplot(x=\"income\", y=\"count\", data=df)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "g.set(xscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "from sklearn.datasets import load_digits, load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold,cross_val_score,\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(new_df, price)\n",
    "reg.predict([[3300]])\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "model.score(X, y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(inputs_n, target)\n",
    "model.score(inputs_n, target)\n",
    "model.predict([[2, 1, 0]])\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_C = SVC(C=1, gamma=10, kernel=\"linear\")\n",
    "model_C.fit(X_train, y_train)\n",
    "model_C.score(X_test, y_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "y_predicted = model.fit_predict(df)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=50, max_iter=100, tol=0.1).fit(train_X, train_y)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[[\"x\", \"y\"]] = scaler.fit_transform(df[[\"x\", \"y\"]])\n",
    "\n",
    "le = LabelEncoder()\n",
    "dfle.town = le.fit_transform(dfle.town)\n",
    "\n",
    "ct = ColumnTransformer([(\"town\", OneHotEncoder(), [0])], remainder=\"passthrough\")\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=10\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\n",
    "    np.average(\n",
    "        cross_val_score(\n",
    "            LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\"), x, y, cv=10\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(np.average(cross_val_score(SVC(gamma=\"auto\"), x, y, cv=10)))\n",
    "print(np.average(cross_val_score(DecisionTreeClassifier(), x, y, cv=10)))\n",
    "print(np.average(cross_val_score(RandomForestClassifier(n_estimators=40), x, y, cv=10)))\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer()\n",
    "X_train_count = v.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted)  # (truth,prediction)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")\n",
    "sn.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Other Functions\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([(\"vectorizer\", CountVectorizer()), (\"nb\", MultinomialNB())])\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "clf.predict(emails)\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model_joblib\")\n",
    "mj = joblib.load(\"model_joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builtin Datasets\n",
    "iris.feature_names\n",
    "iris.target_names\n",
    "iris.data\n",
    "iris.target\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Best Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Models with Different Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"svm\": {\n",
    "        \"model\": svm.SVC(gamma=\"auto\"),\n",
    "        \"params\": {\"C\": [1, 10, 20], \"kernel\": [\"rbf\", \"linear\"]},\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\"n_estimators\": [1, 5, 10]},\n",
    "    },\n",
    "    \"logistic_regression\": {\n",
    "        \"model\": LogisticRegression(solver=\"liblinear\", multi_class=\"auto\"),\n",
    "        \"params\": {\"C\": [1, 5, 10]},\n",
    "    },\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = RandomizedSearchCV(mp[\"model\"], mp[\"params\"], cv=5, return_train_score=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    scores.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"best_score\": clf.best_score_,\n",
    "            \"best_params\": clf.best_params_,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(scores, columns=[\"model\", \"best_score\", \"best_params\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Model with Different Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rs = GridSearchCV(\n",
    "    svm.SVC(gamma=\"auto\"),\n",
    "    {\"C\": [1, 10, 20], \"kernel\": [\"rbf\", \"linear\"]},\n",
    "    cv=5,\n",
    "    return_train_score=False,\n",
    ")\n",
    "rs.fit(iris.data, iris.target)\n",
    "pd.DataFrame(rs.cv_results_)[[\"param_C\", \"param_kernel\", \"mean_test_score\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
